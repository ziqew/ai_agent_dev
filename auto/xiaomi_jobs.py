import asyncio
import json
import traceback
import pandas as pd
from playwright.async_api import async_playwright

TARGET_API = "https://xiaomi.jobs.f.mioffice.cn/api/v1/search/job/posts"


async def main():
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        context = await browser.new_context()
        page = await context.new_page()

        results = []
        seen_pages = set()  # é¿å…é‡å¤

        page.on("response", lambda resp: asyncio.create_task(handle_response(resp, results)))

        entry_url = (
            "https://xiaomi.jobs.f.mioffice.cn/campus/?keywords=&category=&location="
            "&project=7522024429904805997&type=&job_hot_flag=&current=1&limit=10"
            "&functionCategory=&tag=&spread=J7NS6YR"
        )

        print("ğŸš€ æ­£åœ¨æ‰“å¼€é¡µé¢â€¦")
        await page.goto(entry_url, wait_until="networkidle")

        # æŠ“ç¬¬ä¸€é¡µ
        await asyncio.sleep(4)

        total_pages = await get_total_pages(page)
        print(f"ğŸ“„ æ£€æµ‹åˆ°æ€»é¡µæ•°: {total_pages}")

        for current_page in range(1, total_pages + 1):
            if current_page in seen_pages:
                continue
            print(f"\nğŸ“‘ æŠ“å–ç¬¬ {current_page}/{total_pages} é¡µ ...")
            seen_pages.add(current_page)

            await asyncio.sleep(3)

            # ç¿»é¡µé€»è¾‘
            if current_page < total_pages:
                success = await go_to_next_page(page, current_page + 1)
                if not success:
                    print("âš ï¸ ç¿»é¡µå¤±è´¥ï¼Œæå‰ç»“æŸ")
                    break

            await asyncio.sleep(5)  # ç­‰æ¥å£è¯·æ±‚å®Œæˆ

        # ä¿å­˜ç»“æœ
        if results:

            df = pd.DataFrame(results)

            # ===== ä¿å­˜ CSV =====
            csv_path = f"xiaomi_jobs.csv"
            df.to_csv(csv_path, index=False, encoding="utf-8-sig")
            print(f"ğŸ“„ å·²ä¿å­˜ CSVï¼š{csv_path}")

            # ===== ä¿å­˜ JSON =====
            json_path = f"xiaomi_jobs.json"
            df.to_json(json_path, orient="records", force_ascii=False, indent=2)
            print(f"ğŸ’¾ å·²ä¿å­˜ JSONï¼š{json_path}")

            print(f"âœ… å…±ä¿å­˜ {len(df)} æ¡å²—ä½æ•°æ®")
        else:
            print("âš ï¸ æœªæŠ“å–åˆ°ä»»ä½•å²—ä½æ•°æ®")

        await browser.close()


# ---------------- å¤„ç†å“åº” ----------------
async def handle_response(resp, results):
    url = resp.url
    if TARGET_API in url and resp.request.method == "POST":
        try:
            if "application/json" not in resp.headers.get("content-type", ""):
                return
            data = await resp.json()
            posts = data.get("data", {}).get("job_post_list", [])
            for item in posts:
                results.append({
                    "èŒä½": item.get("title", ""),
                    "å…¬å¸": "å°ç±³",
                    "ç±»åˆ«": item.get("job_function", {}).get("name", ""),
                    "å·¥ä½œåœ°ç‚¹": item.get("city_info", {}).get("name", ""),
                    "é“¾æ¥": f"https://xiaomi.jobs.f.mioffice.cn/campus/position/{item.get('id', '')}/detail",
                    "èŒä½æè¿°": item.get("description", ""),
                    "èŒä½è¦æ±‚": item.get("requirement", "")
                })
            print(f"ğŸ“¦ æŠ“åˆ° {len(posts)} æ¡å²—ä½æ•°æ®")
        except Exception as e:
            print("âš ï¸ è§£æå“åº”å¤±è´¥:", e)
            traceback.print_exc()


# ---------------- åˆ†é¡µå‡½æ•° ----------------
async def get_total_pages(page):
    """ä»åˆ†é¡µ HTML ç»“æ„ä¸­æå–æ€»é¡µæ•°"""
    try:
        await page.wait_for_selector("ul.atsx-pagination", timeout=8000)
        items = await page.query_selector_all("ul.atsx-pagination li.atsx-pagination-item")
        pages = []
        for it in items:
            title = await it.get_attribute("title")
            if title and title.isdigit():
                pages.append(int(title))
        total = max(pages) if pages else 1
        return total
    except Exception as e:
        print("âš ï¸ è·å–é¡µæ•°å¤±è´¥:", e)
        return 1


async def go_to_next_page(page, target_page):
    """ç‚¹å‡»é¡µç æˆ–ä¸‹ä¸€é¡µ"""
    try:
        selector = f'li.atsx-pagination-item[title="{target_page}"]'
        target = await page.query_selector(selector)
        if target:
            await target.click()
            print(f"â¡ï¸ ç‚¹å‡»ç¬¬ {target_page} é¡µ")
        else:
            next_btn = await page.query_selector("li.atsx-pagination-next:not(.atsx-pagination-disabled)")
            if next_btn:
                await next_btn.click()
                print("â¡ï¸ ç‚¹å‡»ä¸‹ä¸€é¡µæŒ‰é’®")
            else:
                print("âš ï¸ æ²¡æœ‰æ‰¾åˆ°ä¸‹ä¸€é¡µæŒ‰é’®")
                return False

        await asyncio.sleep(3)
        await page.wait_for_selector("ul.atsx-pagination", timeout=8000)
        return True

    except Exception as e:
        print("âš ï¸ ç¿»é¡µå¤±è´¥:", e)
        return False


if __name__ == "__main__":
    asyncio.run(main())
